{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy import sparse\n",
    "from IPython.display import Image\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#For re-sizing\n",
    "from skimage.transform import resize\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images done\n",
      "100 images done\n",
      "200 images done\n",
      "300 images done\n",
      "400 images done\n",
      "500 images done\n",
      "600 images done\n",
      "700 images done\n",
      "800 images done\n",
      "900 images done\n",
      "1000 images done\n",
      "1100 images done\n",
      "1200 images done\n",
      "1300 images done\n",
      "1400 images done\n",
      "1500 images done\n",
      "1600 images done\n",
      "1700 images done\n",
      "1800 images done\n",
      "1900 images done\n",
      "2000 images done\n",
      "2100 images done\n",
      "2200 images done\n",
      "2300 images done\n",
      "2400 images done\n",
      "2500 images done\n",
      "2600 images done\n",
      "2700 images done\n",
      "2800 images done\n",
      "2900 images done\n",
      "3000 images done\n",
      "3100 images done\n",
      "3200 images done\n",
      "3300 images done\n",
      "3400 images done\n",
      "3500 images done\n",
      "3600 images done\n",
      "3700 images done\n"
     ]
    }
   ],
   "source": [
    "filepath = 'images/'\n",
    "filelist = os.listdir(filepath)\n",
    "\n",
    "image_arrays = []\n",
    "i = 0 \n",
    "i_height = 256\n",
    "i_width = 256\n",
    "for file in filelist:\n",
    "    curPic = load_img(str(filepath) + str(file))\n",
    "    arr = img_to_array(curPic)\n",
    "    img_arr = np.asarray(arr)\n",
    "    img_arr = np.divide(img_arr, float(255))\n",
    "    image = skimage.transform.resize(img_arr, (i_height, i_width, 3), anti_aliasing=True, mode='reflect')\n",
    "    image_arrays.append((str(file), image))\n",
    "    if i % 100 == 0:\n",
    "        print(str(i) + ' images done')\n",
    "    i += 1\n",
    "print(image_arrays[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['postId', 'img_arr', 'likes', 'comments', 'reach', 'hasQuestion', 'hasLike', 'hasComment']\n",
    "mainDF = pd.read_json(\"production.50kInsta.json\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
